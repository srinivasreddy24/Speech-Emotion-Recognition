{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de517150",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_3 (Conv1D)           (None, 40, 64)            384       \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 40, 64)            0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 40, 64)            0         \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 10, 64)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 10, 128)           41088     \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 10, 128)           0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 10, 128)           0         \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 2, 128)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 2, 256)            164096    \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 2, 256)            0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 2, 256)            0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 4104      \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 8)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 209,672\n",
      "Trainable params: 209,672\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "happy\n",
      "Prediction is   happy\n"
     ]
    }
   ],
   "source": [
    "#Import all the necessary libraries\n",
    "from tkinter import *\n",
    "import tkinter\n",
    "import pyaudio\n",
    "import wave\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import keras\n",
    "import librosa\n",
    "from PIL import Image,ImageTk\n",
    "\n",
    "\n",
    "\n",
    "#Define the tkinter instance\n",
    "win= Tk()\n",
    "win.title(\"Speech Emotion Recognition\")\n",
    "\n",
    "#Define the size of the tkinter frame\n",
    "win.geometry(\"700x300\")\n",
    "\n",
    "#Define the working of the button\n",
    "\n",
    "def record():\n",
    "    FRAMES_PER_BUFFER = 3200\n",
    "    FORMAT = pyaudio.paInt16\n",
    "    CHANNELS = 1\n",
    "    RATE = 16000\n",
    "\n",
    "    pa = pyaudio.PyAudio()\n",
    "\n",
    "    stream = pa.open(\n",
    "        format=FORMAT,\n",
    "        channels=CHANNELS,\n",
    "        rate=RATE,\n",
    "        input=True,\n",
    "        frames_per_buffer=FRAMES_PER_BUFFER\n",
    "    )\n",
    "\n",
    "    print('start recording')\n",
    "\n",
    "    seconds = 8\n",
    "    frames = []\n",
    "    second_tracking = 0\n",
    "    second_count = 0\n",
    "    for i in range(0, int(RATE/FRAMES_PER_BUFFER*seconds)):\n",
    "        data = stream.read(FRAMES_PER_BUFFER)\n",
    "        frames.append(data)\n",
    "        second_tracking += 1\n",
    "        if second_tracking == RATE/FRAMES_PER_BUFFER:\n",
    "            second_count += 1\n",
    "            second_tracking = 0\n",
    "            print(f'Time Left: {seconds - second_count} seconds')\n",
    "\n",
    "\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    pa.terminate()\n",
    "\n",
    "    obj = wave.open('liveaudio.wav', 'wb')\n",
    "    obj.setnchannels(CHANNELS)\n",
    "    obj.setsampwidth(pa.get_sample_size(FORMAT))\n",
    "    obj.setframerate(RATE)\n",
    "    obj.writeframes(b''.join(frames))\n",
    "    obj.close()\n",
    "\n",
    "\n",
    "    file = wave.open('liveaudio.wav', 'rb')\n",
    "\n",
    "    sample_freq = file.getframerate()\n",
    "    frames = file.getnframes()\n",
    "    signal_wave = file.readframes(-1)\n",
    "\n",
    "    file.close()\n",
    "\n",
    "    time = frames / sample_freq\n",
    "\n",
    "\n",
    "    # if one channel use int16, if 2 use int32\n",
    "    audio_array = np.frombuffer(signal_wave, dtype=np.int16)\n",
    "\n",
    "    times = np.linspace(0, time, num=frames)\n",
    "\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.plot(times, audio_array)\n",
    "    plt.ylabel('Signal Wave')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.xlim(0, time)\n",
    "    plt.title('The Thing I Just Recorded!!')\n",
    "    plt.show()\n",
    "label=''\n",
    "def predict():\n",
    "    class livePredictions:\n",
    "\n",
    "        def __init__(self, path, file):\n",
    "            self.path = path\n",
    "            self.file = file\n",
    "\n",
    "        def load_model(self):\n",
    "            self.loaded_model = keras.models.load_model(self.path)\n",
    "            return self.loaded_model.summary()\n",
    "\n",
    "        def makepredictions(self):\n",
    "            data, sampling_rate = librosa.load(self.file)\n",
    "            mfccs = np.mean(librosa.feature.mfcc(y=data, sr=sampling_rate, n_mfcc=40).T, axis=0)\n",
    "            x = np.expand_dims(mfccs, axis=1)\n",
    "            x = np.expand_dims(x, axis=0)\n",
    "            #predictions = self.loaded_model.predict_classes(x)\n",
    "\n",
    "            predictions=self.loaded_model.predict(x) \n",
    "            predictions=np.argmax(predictions,axis=1)\n",
    "\n",
    "            print(\"Prediction is\", \" \", self.convertclasstoemotion(predictions))\n",
    "            \n",
    "        @staticmethod\n",
    "        def convertclasstoemotion(pred):\n",
    "            label_conversion = {'0': 'neutral',\n",
    "                                '1': 'calm',\n",
    "                                '2': 'happy',\n",
    "                                '3': 'sad',\n",
    "                                '4': 'angry',\n",
    "                                '5': 'fearful',\n",
    "                                '6': 'disguist',\n",
    "                                '7': 'surprised'}\n",
    "\n",
    "            for key, value in label_conversion.items():\n",
    "                if int(key) == pred:\n",
    "                    label = value\n",
    "            \n",
    "            i1=Image.open('/Users/srinivasreddy/Documents/neutral.jpeg')\n",
    "            n1=i1.resize((180,180))\n",
    "            n1.save('neutral.jpeg')\n",
    "            \n",
    "            i2=Image.open('/Users/srinivasreddy/Documents/calm.jpeg')\n",
    "            n2=i2.resize((180,180))\n",
    "            n2.save('calm.jpeg')\n",
    "            \n",
    "            i3=Image.open('/Users/srinivasreddy/Documents/happy.jpeg')\n",
    "            n3=i3.resize((180,180))\n",
    "            n3.save('happy.jpeg')\n",
    "            \n",
    "            i4=Image.open('/Users/srinivasreddy/Documents/sad.jpeg')\n",
    "            n4=i4.resize((170,170))\n",
    "            n4.save('sad.jpeg')\n",
    "            \n",
    "            i5=Image.open('/Users/srinivasreddy/Documents/angry.png')\n",
    "            n5=i5.resize((170,170))\n",
    "            n5.save('angry.png')\n",
    "            \n",
    "            i6=Image.open('/Users/srinivasreddy/Documents/fearful.jpeg')\n",
    "            n6=i6.resize((180,180))\n",
    "            n6.save('fearful.jpeg')\n",
    "            \n",
    "            i7=Image.open('/Users/srinivasreddy/Documents/disguist.jpeg')\n",
    "            n7=i7.resize((170,170))\n",
    "            n7.save('disguist.jpeg')\n",
    "            \n",
    "            i8=Image.open('/Users/srinivasreddy/Documents/surprise.jpeg')\n",
    "            n8=i8.resize((170,170))\n",
    "            n8.save('surprise.jpeg')\n",
    "            \n",
    "            global ej_image\n",
    "            if label=='neutral':\n",
    "                ej_image=ImageTk.PhotoImage(Image.open('neutral.jpeg'))\n",
    "            elif label=='calm':\n",
    "                ej_image=ImageTk.PhotoImage(Image.open('calm.jpeg'))\n",
    "            elif label=='happy':\n",
    "                ej_image=ImageTk.PhotoImage(Image.open('happy.jpeg'))\n",
    "            elif label=='sad':\n",
    "                ej_image=ImageTk.PhotoImage(Image.open(\"sad.jpeg\"))\n",
    "            elif label=='angry':\n",
    "                ej_image=ImageTk.PhotoImage(Image.open('angry.png'))\n",
    "            elif label=='fearful':\n",
    "                ej_image=ImageTk.PhotoImage(Image.open('fearful.jpeg'))\n",
    "            elif label=='disguist':\n",
    "                ej_image=ImageTk.PhotoImage(Image.open('disguist.jpeg'))\n",
    "            else:\n",
    "                ej_image=ImageTk.PhotoImage(Image.open('surprise.jpeg'))\n",
    "            text.image_create(END,image=ej_image)\n",
    "            print(label)\n",
    "            return label\n",
    "        \n",
    "    pred = livePredictions(path='/Users/srinivasreddy/testing10_model.h5',file='/Users/srinivasreddy/Downloads/TESS Toronto emotional speech set data/OAF_happy/OAF_bean_happy.wav')\n",
    "    pred.load_model()\n",
    "    pred.makepredictions()\n",
    "    \n",
    "    \n",
    "click_btn= PhotoImage(file='/Users/srinivasreddy/Documents/record.png')\n",
    "\n",
    "img_label= Label(image=click_btn)\n",
    "\n",
    "button= Button(win,command= record,borderwidth=10)\n",
    "button.pack(side=LEFT)\n",
    "\n",
    "btn1=Button(win, text='predict',command=predict,borderwidth=5,height= 5, width=10)\n",
    "btn1.place(x=300,y=100)\n",
    "\n",
    "ej_image=PhotoImage(file='/Users/srinivasreddy/Documents/record.png')\n",
    "#text.image_create(END,image=ej_image)\n",
    "\n",
    "text=Text(win,borderwidth=10)\n",
    "#text.pack(side=RIGHT)\n",
    "text.place(x=490, y= 47, width= 200, height= 200)\n",
    "\n",
    "win.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3f9ec8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5bef8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
